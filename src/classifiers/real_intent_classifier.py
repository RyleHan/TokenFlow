import torch
from transformers import AutoTokenizer, AutoModelForCausalLM
from peft import PeftModel
import time
import json
from typing import List, Tuple
import re

class RealIntentClassifier:
    """
    ä½¿ç”¨å¾®è°ƒåçš„Qwen3-0.6Bæ¨¡å‹çš„çœŸå®æ„å›¾è¯†åˆ«å™¨
    æ›¿ä»£MockIntentClassifierï¼Œæä¾›ç›¸åŒçš„æ¥å£
    """
    
    def __init__(self, model_dir: str = "./intent_classifier_model_qwen3"):
        self.model_dir = model_dir
        # ä¸ºäº†é¿å…MPSçš„å†…å­˜é™åˆ¶ï¼Œæ¨ç†æ—¶ä½¿ç”¨CPU
        self.device = torch.device("cpu")
        print(f"RealIntentClassifierä½¿ç”¨è®¾å¤‡: {self.device}")
        
        # æ„å›¾æ˜ å°„
        self.intent_categories = [
            "order_management", "user_auth", "payment", 
            "inventory", "notification", "none"
        ]
        
        self._load_model()
    
    def _load_model(self):
        """åŠ è½½å¾®è°ƒåçš„æ¨¡å‹"""
        try:
            print("æ­£åœ¨åŠ è½½å¾®è°ƒåçš„æ„å›¾è¯†åˆ«æ¨¡å‹...")
            
            # åŠ è½½åˆ†è¯å™¨
            self.tokenizer = AutoTokenizer.from_pretrained(self.model_dir)
            
            # åŠ è½½åŸºç¡€æ¨¡å‹
            base_model = AutoModelForCausalLM.from_pretrained(
                "Qwen/Qwen3-0.6B-Instruct",
                torch_dtype=torch.float32,  # CPUä½¿ç”¨float32
                device_map="cpu",
                trust_remote_code=True
            )
            
            # åŠ è½½LoRAé€‚é…å™¨
            self.model = PeftModel.from_pretrained(base_model, self.model_dir)
            
            # åˆå¹¶é€‚é…å™¨æƒé‡ä»¥æé«˜æ¨ç†é€Ÿåº¦
            self.model = self.model.merge_and_unload()
            
            # ç§»åŠ¨åˆ°CPU
            self.model = self.model.to(self.device)
            self.model.eval()  # è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼
            
            print("âœ… çœŸå®æ„å›¾è¯†åˆ«æ¨¡å‹åŠ è½½å®Œæˆ!")
            
        except Exception as e:
            print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            print("ğŸ’¡ å›é€€åˆ°Mockåˆ†ç±»å™¨...")
            self._fallback_to_mock()
    
    def _fallback_to_mock(self):
        """å›é€€åˆ°Mockåˆ†ç±»å™¨"""
        from intent_classifier import MockIntentClassifier
        self.mock_classifier = MockIntentClassifier()
        self.use_mock = True
        self.model = None
        self.tokenizer = None
        print("âš ï¸ ä½¿ç”¨Mockæ„å›¾åˆ†ç±»å™¨ä½œä¸ºå¤‡ç”¨æ–¹æ¡ˆ")
    
    def _predict_with_model(self, user_prompt: str) -> str:
        """ä½¿ç”¨çœŸå®æ¨¡å‹è¿›è¡Œé¢„æµ‹"""
        if self.model is None or self.tokenizer is None:
            return "none"
        
        try:
            # æ„å»ºè¾“å…¥æ ¼å¼ï¼ˆä¸è®­ç»ƒæ—¶ä¸€è‡´ï¼‰
            input_text = f"ç”¨æˆ·: {user_prompt}\nåŠ©æ‰‹: "
            
            # tokenize
            inputs = self.tokenizer(
                input_text,
                return_tensors="pt",
                truncation=True,
                max_length=256
            )
            
            inputs = {k: v.to(self.device) for k, v in inputs.items()}
            
            # ç”Ÿæˆå“åº”
            with torch.no_grad():
                outputs = self.model.generate(
                    **inputs,
                    max_new_tokens=15,  # å‡å°‘ç”Ÿæˆé•¿åº¦
                    temperature=0.1,
                    do_sample=True,
                    pad_token_id=self.tokenizer.eos_token_id,
                    repetition_penalty=1.1
                )
            
            # è§£ç è¾“å‡º
            full_response = self.tokenizer.decode(outputs[0], skip_special_tokens=True)
            predicted_intent = full_response.split("åŠ©æ‰‹: ")[-1].strip()
            
            # æ¸…ç†å’Œè§£æé¢„æµ‹ç»“æœ
            return self._parse_intent(predicted_intent)
            
        except Exception as e:
            print(f"âš ï¸ æ¨¡å‹é¢„æµ‹å¤±è´¥: {e}")
            return "none"
    
    def _parse_intent(self, raw_output: str) -> str:
        """è§£ææ¨¡å‹è¾“å‡ºï¼Œæå–æ ‡å‡†åŒ–çš„æ„å›¾"""
        if not raw_output:
            return "none"
        
        raw_output = raw_output.lower().strip()
        
        # æ£€æŸ¥æ˜¯å¦åŒ…å«æ ‡å‡†æ„å›¾ç±»åˆ«
        for intent in self.intent_categories:
            if intent in raw_output:
                return intent
        
        # åŸºäºå…³é”®è¯çš„å›é€€è§£æ
        intent_keywords = {
            "order_management": ["è®¢å•", "order", "è´­ä¹°", "ä¸‹å•"],
            "user_auth": ["ç™»å½•", "æ³¨å†Œ", "å¯†ç ", "è´¦æˆ·", "è®¤è¯"],
            "payment": ["æ”¯ä»˜", "ä»˜æ¬¾", "é€€æ¬¾", "äº¤æ˜“"],
            "inventory": ["åº“å­˜", "å•†å“", "æ•°é‡", "ç¼ºè´§"],
            "notification": ["é€šçŸ¥", "æ¶ˆæ¯", "é‚®ä»¶", "æ¨é€"]
        }
        
        for intent, keywords in intent_keywords.items():
            if any(keyword in raw_output for keyword in keywords):
                return intent
        
        return "none"
    
    def predict_intent(self, text: str, threshold: float = 0.05) -> List[Tuple[str, float]]:
        """
        é¢„æµ‹æ–‡æœ¬çš„æ„å›¾
        ä¿æŒä¸MockIntentClassifierç›¸åŒçš„æ¥å£
        """
        # å¦‚æœä½¿ç”¨Mockåˆ†ç±»å™¨
        if hasattr(self, 'use_mock') and self.use_mock:
            return self.mock_classifier.predict_intent(text, threshold)
        
        # ä½¿ç”¨çœŸå®æ¨¡å‹é¢„æµ‹
        predicted_intent = self._predict_with_model(text)
        
        # ä¸ºäº†ä¿æŒæ¥å£ä¸€è‡´æ€§ï¼Œè¿”å›åˆ—è¡¨æ ¼å¼
        if predicted_intent and predicted_intent != "none":
            return [(predicted_intent, 0.9)]  # ç»™ä¸€ä¸ªé«˜ç½®ä¿¡åº¦
        else:
            return [("none", 1.0)]
    
    def predict_top_intent(self, text: str) -> str:
        """è¿”å›æœ€å¯èƒ½çš„å•ä¸ªæ„å›¾"""
        predictions = self.predict_intent(text)
        if predictions:
            return predictions[0][0]
        return "none"
    
    def predict_intents(self, text: str, max_intents: int = 3) -> List[str]:
        """è¿”å›å¤šä¸ªå¯èƒ½çš„æ„å›¾ï¼ˆç”¨äºå¤šæ„å›¾åœºæ™¯ï¼‰"""
        predictions = self.predict_intent(text)
        return [intent for intent, score in predictions[:max_intents]]

def test_real_intent_classifier():
    """æµ‹è¯•çœŸå®æ„å›¾è¯†åˆ«å™¨"""
    classifier = RealIntentClassifier()
    
    test_cases = [
        "æˆ‘æƒ³æŸ¥çœ‹æˆ‘çš„è®¢å•çŠ¶æ€",
        "æ€ä¹ˆç™»å½•æˆ‘çš„è´¦æˆ·", 
        "æ”¯ä»˜å¤±è´¥äº†æ€ä¹ˆåŠ",
        "åº“å­˜ä¸å¤Ÿæ€ä¹ˆå¤„ç†",
        "æ€ä¹ˆå‘é€é€šçŸ¥ç»™ç”¨æˆ·",
        "ä»Šå¤©å¤©æ°”æ€ä¹ˆæ ·"
    ]
    
    print("=== çœŸå®æ„å›¾è¯†åˆ«å™¨æµ‹è¯• ===\n")
    
    for text in test_cases:
        start_time = time.time()
        top_intent = classifier.predict_top_intent(text)
        predictions = classifier.predict_intent(text)
        inference_time = time.time() - start_time
        
        print(f"è¾“å…¥: {text}")
        print(f"é¢„æµ‹æ„å›¾: {top_intent}")
        print(f"æ¨ç†æ—¶é—´: {inference_time:.3f}s")
        print(f"è¯¦ç»†é¢„æµ‹: {predictions}")
        print("-" * 50)

if __name__ == "__main__":
    test_real_intent_classifier()