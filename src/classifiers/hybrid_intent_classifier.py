#!/usr/bin/env python3
"""
æ··åˆæ„å›¾åˆ†ç±»å™¨ï¼šç»“åˆè§„åˆ™åŒ¹é…å’Œç¥ç»ç½‘ç»œ
ç›®æ ‡ï¼šåˆ©ç”¨Mockåˆ†ç±»å™¨çš„é«˜å‡†ç¡®ç‡ + ç¥ç»ç½‘ç»œçš„æ³›åŒ–èƒ½åŠ›
"""

import torch
from transformers import AutoTokenizer, AutoModelForCausalLM
from peft import PeftModel
import numpy as np
from typing import List, Dict, Tuple, Optional
import re
from sentence_transformers import SentenceTransformer
import json

class HybridIntentClassifier:
    def __init__(self, model_path: Optional[str] = None, use_finetuned: bool = True):
        self.intent_categories = [
            "order_management", "user_auth", "payment", 
            "inventory", "notification", "none"
        ]
        
        # æƒé‡é…ç½® - å¾®è°ƒæ¨¡å‹æƒé‡æ›´é«˜
        if use_finetuned:
            self.rule_weight = 0.3  # è§„åˆ™åŒ¹é…æƒé‡
            self.neural_weight = 0.7  # ç¥ç»ç½‘ç»œæƒé‡
        else:
            self.rule_weight = 0.7  # è§„åˆ™åŒ¹é…æƒé‡
            self.neural_weight = 0.3  # ç¥ç»ç½‘ç»œæƒé‡
        
        self.use_finetuned = use_finetuned
        
        # åˆå§‹åŒ–å„ä¸ªç»„ä»¶
        self._init_rule_classifier()
        self._init_neural_classifier(model_path)
        self._init_semantic_matcher()
        
        print(f"ğŸ”§ æ··åˆåˆ†ç±»å™¨åˆå§‹åŒ–å®Œæˆ")
        print(f"ğŸ“Š æƒé‡é…ç½®: è§„åˆ™={self.rule_weight}, ç¥ç»ç½‘ç»œ={self.neural_weight}")
        print(f"ğŸ¯ ä½¿ç”¨å¾®è°ƒæ¨¡å‹: {self.use_finetuned}")

    def _init_rule_classifier(self):
        """åˆå§‹åŒ–è§„åˆ™åˆ†ç±»å™¨ï¼ˆåŸºäºMockåˆ†ç±»å™¨ï¼‰"""
        self.intent_keywords = {
            "order_management": [
                "è®¢å•", "ä¸‹å•", "è´­ä¹°", "ä¹°", "å•†å“", "äº§å“", "è´­ç‰©è½¦", "ç»“ç®—", 
                "checkout", "order", "è´­ç‰©", "ä¸‹è®¢å•", "å•†å“ä¿¡æ¯", "äº§å“è¯¦æƒ…"
            ],
            "user_auth": [
                "ç™»å½•", "æ³¨å†Œ", "è´¦æˆ·", "è´¦å·", "å¯†ç ", "ç”¨æˆ·å", "è®¤è¯", "éªŒè¯",
                "login", "register", "account", "ç”¨æˆ·", "èº«ä»½", "æƒé™"
            ],
            "payment": [
                "æ”¯ä»˜", "ä»˜æ¬¾", "è´¹ç”¨", "ä»·æ ¼", "é‡‘é¢", "è´¦å•", "æ‰£è´¹", "å……å€¼",
                "payment", "pay", "é’±", "ä½™é¢", "æ”¶è´¹", "é€€æ¬¾"
            ],
            "inventory": [
                "åº“å­˜", "ç°è´§", "æœ‰è´§", "ç¼ºè´§", "è¡¥è´§", "è¿›è´§", "å‡ºè´§", "ç›˜ç‚¹",
                "inventory", "stock", "å­˜è´§", "ä»“åº“", "åº“æˆ¿"
            ],
            "notification": [
                "é€šçŸ¥", "æé†’", "æ¶ˆæ¯", "æ¨é€", "é‚®ä»¶", "çŸ­ä¿¡", "æç¤º", "è­¦å‘Š",
                "notification", "message", "alert", "æ¶ˆæ¯æé†’"
            ]
        }
        
        # è¯­ä¹‰ç›¸ä¼¼åº¦åŸºå‡†å¥å­
        self.intent_examples = {
            "order_management": ["æˆ‘æƒ³æŸ¥çœ‹æˆ‘çš„è®¢å•", "å¦‚ä½•ä¸‹å•è´­ä¹°å•†å“", "è´­ç‰©è½¦ç»“ç®—"],
            "user_auth": ["æ€ä¹ˆç™»å½•è´¦æˆ·", "å¿˜è®°å¯†ç äº†", "æ³¨å†Œæ–°ç”¨æˆ·"],
            "payment": ["æ”¯ä»˜å¤±è´¥äº†", "æ€ä¹ˆä»˜æ¬¾", "æŸ¥çœ‹è´¦å•è´¹ç”¨"],
            "inventory": ["åº“å­˜ä¸è¶³", "æŸ¥çœ‹ç°è´§æƒ…å†µ", "è¡¥è´§é€šçŸ¥"],
            "notification": ["å‘é€æé†’æ¶ˆæ¯", "è®¾ç½®é€šçŸ¥", "æŸ¥çœ‹æ¨é€"],
            "none": ["ä»Šå¤©å¤©æ°”æ€ä¹ˆæ ·", "æ¨èä¸€éƒ¨ç”µå½±", "ä»€ä¹ˆæ˜¯äººå·¥æ™ºèƒ½"]
        }

    def _init_neural_classifier(self, model_path: Optional[str]):
        """åˆå§‹åŒ–ç¥ç»ç½‘ç»œåˆ†ç±»å™¨"""
        # å¦‚æœæ²¡æœ‰æŒ‡å®šè·¯å¾„ä¸”ä½¿ç”¨å¾®è°ƒæ¨¡å‹ï¼Œä½¿ç”¨é»˜è®¤çš„å¾®è°ƒæ¨¡å‹è·¯å¾„
        if model_path is None and self.use_finetuned:
            model_path = "models/qwen3_fixed_classifier"
        
        if model_path and self._model_exists(model_path):
            try:
                print(f"ğŸ“¥ åŠ è½½ç¥ç»ç½‘ç»œæ¨¡å‹: {model_path}")
                
                # è®¾ç½®è®¾å¤‡
                if torch.backends.mps.is_available():
                    self.device = torch.device("mps")
                    print("âœ… ä½¿ç”¨MPSåŠ é€Ÿ")
                else:
                    self.device = torch.device("cpu")
                    print("âš ï¸ ä½¿ç”¨CPU")
                
                # åŠ è½½tokenizer
                if self.use_finetuned:
                    # å¾®è°ƒæ¨¡å‹ä½¿ç”¨è‡ªå·±çš„tokenizer
                    self.tokenizer = AutoTokenizer.from_pretrained(
                        model_path, trust_remote_code=True
                    )
                    base_model_name = "Qwen/Qwen3-0.6B"
                else:
                    # åŸæœ‰æ¨¡å‹é€»è¾‘
                    self.tokenizer = AutoTokenizer.from_pretrained(model_path)
                    base_model_name = "Qwen/Qwen2.5-0.5B-Instruct"
                
                if self.tokenizer.pad_token is None:
                    self.tokenizer.pad_token = self.tokenizer.eos_token
                
                # åŠ è½½åŸºç¡€æ¨¡å‹
                base_model = AutoModelForCausalLM.from_pretrained(
                    base_model_name,
                    torch_dtype=torch.float32,
                    trust_remote_code=True,
                    low_cpu_mem_usage=True,
                )
                
                # åŠ è½½PEFTæ¨¡å‹
                self.neural_model = PeftModel.from_pretrained(base_model, model_path)
                self.neural_model.eval()
                self.neural_model = self.neural_model.to(self.device)
                
                # ç¦ç”¨æ¢¯åº¦è®¡ç®—
                for param in self.neural_model.parameters():
                    param.requires_grad = False
                
                self.neural_available = True
                print("âœ… ç¥ç»ç½‘ç»œæ¨¡å‹åŠ è½½æˆåŠŸ")
                
            except Exception as e:
                print(f"âš ï¸ ç¥ç»ç½‘ç»œæ¨¡å‹åŠ è½½å¤±è´¥: {e}")
                self.neural_available = False
        else:
            print("âš ï¸ ç¥ç»ç½‘ç»œæ¨¡å‹ä¸å¯ç”¨ï¼Œä½¿ç”¨çº¯è§„åˆ™æ¨¡å¼")
            self.neural_available = False

    def _init_semantic_matcher(self):
        """åˆå§‹åŒ–è¯­ä¹‰åŒ¹é…å™¨"""
        try:
            print("ğŸ“¥ åŠ è½½è¯­ä¹‰åŒ¹é…æ¨¡å‹...")
            self.semantic_model = SentenceTransformer('all-MiniLM-L6-v2')
            
            # é¢„è®¡ç®—æ„å›¾ç¤ºä¾‹çš„åµŒå…¥
            self.intent_embeddings = {}
            for intent, examples in self.intent_examples.items():
                embeddings = self.semantic_model.encode(examples)
                self.intent_embeddings[intent] = np.mean(embeddings, axis=0)
            
            self.semantic_available = True
            print("âœ… è¯­ä¹‰åŒ¹é…å™¨åˆå§‹åŒ–æˆåŠŸ")
        except Exception as e:
            print(f"âš ï¸ è¯­ä¹‰åŒ¹é…å™¨åˆå§‹åŒ–å¤±è´¥: {e}")
            self.semantic_available = False

    def _model_exists(self, path: str) -> bool:
        """æ£€æŸ¥æ¨¡å‹æ˜¯å¦å­˜åœ¨"""
        import os
        return os.path.exists(path) and os.path.exists(os.path.join(path, "adapter_config.json"))

    def classify_by_rules(self, text: str) -> Dict[str, float]:
        """åŸºäºè§„åˆ™çš„åˆ†ç±»"""
        text_lower = text.lower()
        scores = {intent: 0.0 for intent in self.intent_categories}
        
        # å…³é”®è¯åŒ¹é…
        for intent, keywords in self.intent_keywords.items():
            for keyword in keywords:
                if keyword.lower() in text_lower:
                    scores[intent] += 1.0
        
        # è¯­ä¹‰ç›¸ä¼¼åº¦åŒ¹é…ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        if self.semantic_available:
            query_embedding = self.semantic_model.encode([text])
            for intent, intent_embedding in self.intent_embeddings.items():
                similarity = np.dot(query_embedding[0], intent_embedding) / (
                    np.linalg.norm(query_embedding[0]) * np.linalg.norm(intent_embedding)
                )
                scores[intent] += similarity * 0.5  # è¯­ä¹‰ç›¸ä¼¼åº¦æƒé‡
        
        # å½’ä¸€åŒ–
        total_score = sum(scores.values())
        if total_score > 0:
            scores = {k: v / total_score for k, v in scores.items()}
        else:
            scores["none"] = 1.0
        
        return scores

    def classify_by_neural(self, text: str) -> Dict[str, float]:
        """åŸºäºç¥ç»ç½‘ç»œçš„åˆ†ç±»"""
        if not self.neural_available:
            return {intent: 1.0/len(self.intent_categories) for intent in self.intent_categories}
        
        try:
            if self.use_finetuned:
                # ä½¿ç”¨å¾®è°ƒæ¨¡å‹çš„æ ¼å¼
                prompt = f"ç”¨æˆ·: {text}\\nåŠ©æ‰‹: "
            else:
                # åŸæœ‰æ¨¡å‹æ ¼å¼
                prompt = f"åˆ†ç±»æ„å›¾: {text}\\næ„å›¾:"
            
            # Tokenize
            inputs = self.tokenizer(
                prompt, 
                return_tensors="pt", 
                max_length=256, 
                truncation=True
            )
            
            # ç§»åŠ¨åˆ°æ­£ç¡®è®¾å¤‡
            if self.device.type != "cpu":
                inputs = {k: v.to(self.device) for k, v in inputs.items()}
            
            # ç”Ÿæˆ
            with torch.no_grad():
                outputs = self.neural_model.generate(
                    **inputs,
                    max_new_tokens=25,  # å¢åŠ ç”Ÿæˆé•¿åº¦ä»¥é€‚åº”å¤šæ„å›¾
                    temperature=0.1,
                    do_sample=True,
                    pad_token_id=self.tokenizer.eos_token_id,
                    repetition_penalty=1.1
                )
            
            # è§£ç 
            generated_text = self.tokenizer.decode(outputs[0], skip_special_tokens=True)
            predicted_intents = self._parse_neural_output(generated_text)
            
            # è½¬æ¢ä¸ºæ¦‚ç‡åˆ†å¸ƒ
            scores = {intent: 0.05 for intent in self.intent_categories}  # åŸºç¡€æ¦‚ç‡
            
            if predicted_intents:
                # åˆ†é…æ¦‚ç‡ç»™é¢„æµ‹çš„æ„å›¾
                prob_per_intent = 0.9 / len(predicted_intents)
                for intent in predicted_intents:
                    if intent in self.intent_categories:
                        scores[intent] = prob_per_intent
            else:
                scores["none"] = 0.9
            
            return scores
            
        except Exception as e:
            print(f"âš ï¸ ç¥ç»ç½‘ç»œæ¨ç†å¤±è´¥: {e}")
            return {intent: 1.0/len(self.intent_categories) for intent in self.intent_categories}

    def _parse_neural_output(self, output: str) -> List[str]:
        """è§£æç¥ç»ç½‘ç»œè¾“å‡ºï¼Œæ”¯æŒå¤šæ„å›¾"""
        if self.use_finetuned:
            # å¾®è°ƒæ¨¡å‹æ ¼å¼è§£æ
            if "åŠ©æ‰‹: " in output:
                intent_part = output.split("åŠ©æ‰‹: ")[-1].strip()
            else:
                intent_part = output.strip()
        else:
            # åŸæœ‰æ ¼å¼è§£æ
            if "æ„å›¾:" in output:
                intent_part = output.split("æ„å›¾:")[-1].strip()
            else:
                intent_part = output.strip()
        
        # æ¸…ç†å’Œæ ‡å‡†åŒ–
        intent_part = intent_part.lower().replace("\\n", " ")
        
        # æå–æ„å›¾
        found_intents = []
        for intent in self.intent_categories:
            if intent != "none":  # å…ˆæ£€æŸ¥ä¸šåŠ¡æ„å›¾
                intent_clean = intent.replace("_", "")
                if intent in intent_part or intent_clean in intent_part.replace("_", ""):
                    found_intents.append(intent)
        
        # åå¤„ç†ï¼šç§»é™¤å¤šä½™çš„noneé¢„æµ‹ï¼ˆæ ¹æ®æˆ‘ä»¬çš„åˆ†æï¼‰
        if found_intents:
            return found_intents
        
        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°ä¸šåŠ¡æ„å›¾ï¼Œæ£€æŸ¥æ˜¯å¦ä¸ºnone
        if "none" in intent_part or not found_intents:
            return ["none"]
        
        return found_intents if found_intents else ["none"]

    def classify(self, text: str) -> Dict[str, any]:
        """æ··åˆåˆ†ç±»ï¼Œæ”¯æŒå¤šæ„å›¾"""
        # è§„åˆ™åˆ†ç±»
        rule_scores = self.classify_by_rules(text)
        
        # ç¥ç»ç½‘ç»œåˆ†ç±»
        neural_scores = self.classify_by_neural(text)
        
        # åŠ æƒèåˆ
        final_scores = {}
        for intent in self.intent_categories:
            final_scores[intent] = (
                self.rule_weight * rule_scores.get(intent, 0) +
                self.neural_weight * neural_scores.get(intent, 0)
            )
        
        # å¤šæ„å›¾æ”¯æŒï¼šé€‰æ‹©æ‰€æœ‰è¶…è¿‡é˜ˆå€¼çš„æ„å›¾
        threshold = 0.3 if self.use_finetuned else 0.5
        predicted_intents = []
        
        for intent, score in final_scores.items():
            if score >= threshold and intent != "none":
                predicted_intents.append(intent)
        
        # å¦‚æœæ²¡æœ‰ä¸šåŠ¡æ„å›¾ï¼Œè¿”å›none
        if not predicted_intents:
            predicted_intents = ["none"]
        
        # ä¸»è¦æ„å›¾ï¼ˆæœ€é«˜åˆ†ï¼‰
        primary_intent = max(final_scores, key=final_scores.get)
        primary_confidence = final_scores[primary_intent]
        
        return {
            "intent": primary_intent,  # å…¼å®¹æ€§ï¼šä¸»è¦æ„å›¾
            "intents": predicted_intents,  # å¤šæ„å›¾ç»“æœ
            "confidence": primary_confidence,
            "rule_scores": rule_scores,
            "neural_scores": neural_scores,
            "final_scores": final_scores,
            "threshold": threshold
        }

    def predict_intent(self, text: str) -> str:
        """ç®€åŒ–çš„é¢„æµ‹æ¥å£ï¼Œä¸ç°æœ‰ä»£ç å…¼å®¹"""
        result = self.classify(text)
        return result["intent"]

    def batch_classify(self, texts: List[str]) -> List[Dict]:
        """æ‰¹é‡åˆ†ç±»"""
        return [self.classify(text) for text in texts]

def test_hybrid_classifier():
    """æµ‹è¯•æ··åˆåˆ†ç±»å™¨"""
    print("ğŸ§ª æµ‹è¯•æ··åˆåˆ†ç±»å™¨...")
    
    # åˆ›å»ºåˆ†ç±»å™¨ - ä½¿ç”¨å¾®è°ƒæ¨¡å‹
    classifier = HybridIntentClassifier(use_finetuned=True)
    
    # æµ‹è¯•ç”¨ä¾‹
    test_cases = [
        "æˆ‘æƒ³æŸ¥çœ‹æˆ‘çš„è®¢å•çŠ¶æ€",
        "æ€ä¹ˆç™»å½•æˆ‘çš„è´¦æˆ·",
        "æ”¯ä»˜å¤±è´¥äº†æ€ä¹ˆåŠ",
        "åº“å­˜ä¸è¶³æ€ä¹ˆå¤„ç†",
        "å‘é€é€šçŸ¥æ¶ˆæ¯",
        "ä»Šå¤©å¤©æ°”æ€ä¹ˆæ ·",
        "ç”¨æˆ·ç™»å½•åæŸ¥çœ‹è®¢å•",  # å¤šæ„å›¾æ ·æœ¬
        "æ”¯ä»˜æˆåŠŸåå‘é€é€šçŸ¥",   # å¤šæ„å›¾æ ·æœ¬
        "ä¿®æ”¹èº«ä»½è¦æ˜¯æœ‰é—®é¢˜å°±ä»˜æ¬¾å……å€¼",  # å¤æ‚å¤šæ„å›¾
        "å› ä¸ºè´¦å•é—®é¢˜éœ€è¦æ”¯ä»˜å› ä¸ºæ ‡è®°çŸ­ä¿¡",  # å¤æ‚å¤šæ„å›¾
    ]
    
    print("\\nğŸ“Š åˆ†ç±»ç»“æœ:")
    print("-" * 80)
    
    for text in test_cases:
        result = classifier.classify(text)
        print(f"è¾“å…¥: {text}")
        print(f"ä¸»æ„å›¾: {result['intent']} (ç½®ä¿¡åº¦: {result['confidence']:.3f})")
        print(f"æ‰€æœ‰æ„å›¾: {result['intents']}")
        print(f"é˜ˆå€¼: {result['threshold']}")
        print(f"æœ€ç»ˆåˆ†æ•°: {result['final_scores']}")
        print("-" * 80)

if __name__ == "__main__":
    test_hybrid_classifier()