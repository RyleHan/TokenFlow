#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
æµ‹è¯•å¾®è°ƒæ¨¡å‹çš„TokenèŠ‚çœæ•ˆæœ
å¯¹æ¯”å¾®è°ƒå‰åçš„æ£€ç´¢ç²¾åº¦å’ŒTokenä½¿ç”¨é‡
"""

import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from src.core.retriever import DocumentRetriever
from src.classifiers.hybrid_intent_classifier import HybridIntentClassifier
from src.classifiers.mock_intent_classifier import MockIntentClassifier
from src.core.large_llm_simulator import LargeLLMSimulator
import json
import time
from typing import Dict, List, Any

class TokenSavingsAnalyzer:
    """TokenèŠ‚çœæ•ˆæœåˆ†æå™¨"""
    
    def __init__(self):
        print("ğŸ”§ åˆå§‹åŒ–TokenèŠ‚çœåˆ†æå™¨...")
        
        # åˆå§‹åŒ–æ–‡æ¡£æ£€ç´¢å™¨
        self.retriever = DocumentRetriever()
        self.retriever.initialize()
        
        # åˆå§‹åŒ–LLMæ¨¡æ‹Ÿå™¨
        self.llm_simulator = LargeLLMSimulator()
        
        # åˆå§‹åŒ–ä¸åŒçš„åˆ†ç±»å™¨
        print("ğŸ“¥ åˆå§‹åŒ–åŸºå‡†åˆ†ç±»å™¨...")
        self.mock_classifier = MockIntentClassifier()
        
        print("ğŸ“¥ åˆå§‹åŒ–å¾®è°ƒæ··åˆåˆ†ç±»å™¨...")
        self.finetuned_classifier = HybridIntentClassifier(use_finetuned=True)
        
        print("ğŸ“¥ åˆå§‹åŒ–è§„åˆ™åˆ†ç±»å™¨...")
        self.rule_classifier = HybridIntentClassifier(use_finetuned=False)
        
        # æµ‹è¯•æ ·æœ¬
        self.test_cases = [
            {
                "prompt": "æˆ‘æƒ³æŸ¥çœ‹æˆ‘çš„è®¢å•çŠ¶æ€",
                "expected_intents": ["order_management"],
                "description": "å•æ„å›¾-è®¢å•æŸ¥è¯¢"
            },
            {
                "prompt": "ç™»å½•åæŸ¥çœ‹è®¢å•å¹¶å¤„ç†æ”¯ä»˜",
                "expected_intents": ["user_auth", "order_management", "payment"],
                "description": "å¤šæ„å›¾-ç”¨æˆ·è®¤è¯+è®¢å•+æ”¯ä»˜"
            },
            {
                "prompt": "æ”¯ä»˜æˆåŠŸåå‘é€é€šçŸ¥",
                "expected_intents": ["payment", "notification"],
                "description": "å¤šæ„å›¾-æ”¯ä»˜+é€šçŸ¥"
            },
            {
                "prompt": "åº“å­˜ä¸è¶³æ—¶éœ€è¦åŠæ—¶æé†’",
                "expected_intents": ["inventory", "notification"],
                "description": "å¤šæ„å›¾-åº“å­˜+é€šçŸ¥"
            },
            {
                "prompt": "ç”¨æˆ·æ³¨å†Œã€è®¢å•å¤„ç†å’Œæ”¯ä»˜ç¡®è®¤",
                "expected_intents": ["user_auth", "order_management", "payment"],
                "description": "å¤æ‚å¤šæ„å›¾"
            },
            {
                "prompt": "ä»Šå¤©å¤©æ°”æ€ä¹ˆæ ·",
                "expected_intents": ["none"],
                "description": "æ— å…³æŸ¥è¯¢"
            },
            {
                "prompt": "å¸®æˆ‘æŸ¥è¯¢è´¦æˆ·ä½™é¢å’Œè®¢å•ä¿¡æ¯",
                "expected_intents": ["user_auth", "order_management"],
                "description": "å¤šæ„å›¾-è´¦æˆ·+è®¢å•"
            },
            {
                "prompt": "è®¢å•æ”¯ä»˜å¤±è´¥ï¼Œéœ€è¦é‡æ–°ä»˜æ¬¾",
                "expected_intents": ["order_management", "payment"],
                "description": "å¤šæ„å›¾-è®¢å•+æ”¯ä»˜é—®é¢˜"
            }
        ]
    
    def run_classification_test(self, prompt: str) -> Dict[str, Any]:
        """è¿è¡Œå•ä¸ªåˆ†ç±»æµ‹è¯•"""
        
        # 1. Mockåˆ†ç±»å™¨
        mock_intent = self.mock_classifier.predict_intent(prompt)
        mock_intents = [mock_intent] if mock_intent != "none" else ["none"]
        
        # 2. å¾®è°ƒæ··åˆåˆ†ç±»å™¨
        finetuned_result = self.finetuned_classifier.classify(prompt)
        finetuned_intents = finetuned_result.get("intents", [finetuned_result.get("intent", "none")])
        
        # 3. è§„åˆ™åˆ†ç±»å™¨
        rule_result = self.rule_classifier.classify(prompt)
        rule_intents = rule_result.get("intents", [rule_result.get("intent", "none")])
        
        return {
            "mock": {
                "intents": mock_intents,
                "confidence": 1.0,  # Mockåˆ†ç±»å™¨æ€»æ˜¯å¾ˆç¡®å®š
                "details": "åŸºäºè§„åˆ™çš„Mockåˆ†ç±»å™¨"
            },
            "finetuned": {
                "intents": finetuned_intents,
                "confidence": finetuned_result.get("confidence", 0.0),
                "details": finetuned_result
            },
            "rule_only": {
                "intents": rule_intents,
                "confidence": rule_result.get("confidence", 0.0),
                "details": rule_result
            }
        }
    
    def calculate_document_relevance(self, prompt: str, intents: List[str], max_docs: int = 5) -> Dict[str, Any]:
        """è®¡ç®—æ–‡æ¡£æ£€ç´¢çš„ç›¸å…³æ€§å’Œtokenä½¿ç”¨"""
        
        # æ— è¿‡æ»¤ï¼šç›´æ¥æ£€ç´¢
        no_filter_docs = self.retriever.retrieve_docs(prompt, top_k=max_docs)
        
        # æ„å›¾è¿‡æ»¤ï¼šåŸºäºæ„å›¾å¢å¼ºæŸ¥è¯¢
        if "none" not in intents:
            intent_query = f"{prompt} {' '.join(intents)}"
            filtered_docs = self.retriever.retrieve_docs(intent_query, top_k=max_docs)
        else:
            filtered_docs = self.retriever.retrieve_docs(prompt, top_k=2)  # å‡å°‘æ— å…³æŸ¥è¯¢çš„æ–‡æ¡£æ•°
        
        # ä¼°ç®—tokenä½¿ç”¨é‡
        def estimate_tokens(docs):
            total_tokens = 0
            for doc in docs:
                # ç²—ç•¥ä¼°ç®—ï¼šä¸­æ–‡å­—ç¬¦æ•° * 1.5
                content_length = len(doc.get('chunk_content', ''))
                tokens = int(content_length * 1.5)
                total_tokens += tokens
            return total_tokens
        
        no_filter_tokens = estimate_tokens(no_filter_docs)
        filtered_tokens = estimate_tokens(filtered_docs)
        
        return {
            "no_filter": {
                "docs_count": len(no_filter_docs),
                "estimated_tokens": no_filter_tokens,
                "docs": no_filter_docs
            },
            "with_filter": {
                "docs_count": len(filtered_docs),
                "estimated_tokens": filtered_tokens,
                "docs": filtered_docs
            },
            "token_savings": {
                "absolute": no_filter_tokens - filtered_tokens,
                "percentage": ((no_filter_tokens - filtered_tokens) / no_filter_tokens * 100) if no_filter_tokens > 0 else 0
            }
        }
    
    def run_comprehensive_test(self) -> Dict[str, Any]:
        """è¿è¡Œå…¨é¢æµ‹è¯•"""
        print("ğŸš€ å¼€å§‹å…¨é¢TokenèŠ‚çœæ•ˆæœæµ‹è¯•...")
        
        results = {
            "test_info": {
                "timestamp": time.strftime("%Y-%m-%d %H:%M:%S"),
                "total_test_cases": len(self.test_cases),
                "classifiers": ["Mock", "å¾®è°ƒæ··åˆ", "çº¯è§„åˆ™"]
            },
            "individual_results": [],
            "summary_stats": {}
        }
        
        total_token_savings = {"mock": 0, "finetuned": 0, "rule_only": 0}
        total_accuracy = {"mock": 0, "finetuned": 0, "rule_only": 0}
        
        for i, test_case in enumerate(self.test_cases):
            print(f"\\nğŸ“‹ æµ‹è¯•æ¡ˆä¾‹ {i+1}/{len(self.test_cases)}: {test_case['description']}")
            print(f"   è¾“å…¥: {test_case['prompt']}")
            print(f"   æœŸæœ›æ„å›¾: {test_case['expected_intents']}")
            
            # åˆ†ç±»æµ‹è¯•
            classification_results = self.run_classification_test(test_case['prompt'])
            
            # æ–‡æ¡£æ£€ç´¢å’Œtokenè®¡ç®—
            doc_results = {}
            for classifier_name, class_result in classification_results.items():
                intents = class_result['intents']
                doc_result = self.calculate_document_relevance(
                    test_case['prompt'], 
                    intents, 
                    max_docs=5
                )
                doc_results[classifier_name] = doc_result
                
                # ç´¯è®¡tokenèŠ‚çœ
                total_token_savings[classifier_name] += doc_result['token_savings']['absolute']
                
                # è®¡ç®—å‡†ç¡®ç‡
                expected_set = set(test_case['expected_intents'])
                predicted_set = set(intents)
                
                if expected_set == predicted_set:
                    accuracy = 1.0
                elif expected_set & predicted_set:  # æœ‰äº¤é›†
                    accuracy = len(expected_set & predicted_set) / len(expected_set | predicted_set)
                else:
                    accuracy = 0.0
                
                total_accuracy[classifier_name] += accuracy
                
                print(f"   {classifier_name:12}: {intents} (å‡†ç¡®ç‡: {accuracy:.2f}, TokenèŠ‚çœ: {doc_result['token_savings']['absolute']})")
            
            # ä¿å­˜å•ä¸ªæµ‹è¯•ç»“æœ
            test_result = {
                "test_case": test_case,
                "classification_results": classification_results,
                "document_retrieval": doc_results
            }
            results["individual_results"].append(test_result)
        
        # è®¡ç®—æ€»ä½“ç»Ÿè®¡
        num_cases = len(self.test_cases)
        results["summary_stats"] = {
            "average_accuracy": {
                "mock": total_accuracy["mock"] / num_cases,
                "finetuned": total_accuracy["finetuned"] / num_cases,
                "rule_only": total_accuracy["rule_only"] / num_cases
            },
            "total_token_savings": total_token_savings,
            "average_token_savings": {
                "mock": total_token_savings["mock"] / num_cases,
                "finetuned": total_token_savings["finetuned"] / num_cases,
                "rule_only": total_token_savings["rule_only"] / num_cases
            }
        }
        
        return results
    
    def generate_report(self, results: Dict[str, Any]):
        """ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š"""
        print("\\n" + "="*80)
        print("ğŸ¯ TokenèŠ‚çœæ•ˆæœæµ‹è¯•æŠ¥å‘Š")
        print("="*80)
        
        stats = results["summary_stats"]
        
        print("\\nğŸ“Š åˆ†ç±»å™¨æ€§èƒ½å¯¹æ¯”:")
        print("-"*60)
        print(f"{'åˆ†ç±»å™¨':<15} {'å¹³å‡å‡†ç¡®ç‡':<12} {'å¹³å‡TokenèŠ‚çœ':<15}")
        print("-"*60)
        
        for classifier in ["mock", "finetuned", "rule_only"]:
            name_map = {"mock": "Mockåˆ†ç±»å™¨", "finetuned": "å¾®è°ƒæ··åˆ", "rule_only": "çº¯è§„åˆ™"}
            accuracy = stats["average_accuracy"][classifier]
            avg_savings = stats["average_token_savings"][classifier]
            
            print(f"{name_map[classifier]:<15} {accuracy:<12.3f} {avg_savings:<15.1f}")
        
        print("\\nğŸ’¡ å…³é”®å‘ç°:")
        
        # æ‰¾å‡ºæœ€ä½³åˆ†ç±»å™¨
        best_accuracy = max(stats["average_accuracy"].values())
        best_savings = max(stats["average_token_savings"].values())
        
        best_acc_classifier = max(stats["average_accuracy"], key=stats["average_accuracy"].get)
        best_savings_classifier = max(stats["average_token_savings"], key=stats["average_token_savings"].get)
        
        name_map = {"mock": "Mockåˆ†ç±»å™¨", "finetuned": "å¾®è°ƒæ··åˆåˆ†ç±»å™¨", "rule_only": "çº¯è§„åˆ™åˆ†ç±»å™¨"}
        
        print(f"  âœ… æœ€é«˜å‡†ç¡®ç‡: {name_map[best_acc_classifier]} ({best_accuracy:.3f})")
        print(f"  âœ… æœ€å¤§TokenèŠ‚çœ: {name_map[best_savings_classifier]} ({best_savings:.1f} tokens)")
        
        # å¾®è°ƒæ•ˆæœåˆ†æ
        finetuned_acc = stats["average_accuracy"]["finetuned"]
        mock_acc = stats["average_accuracy"]["mock"]
        improvement = finetuned_acc - mock_acc
        
        print(f"\\nğŸš€ å¾®è°ƒæ•ˆæœè¯„ä¼°:")
        print(f"  ğŸ“ˆ å‡†ç¡®ç‡æ”¹è¿›: {improvement:+.3f} ({improvement/mock_acc*100:+.1f}%)")
        
        finetuned_savings = stats["average_token_savings"]["finetuned"]
        mock_savings = stats["average_token_savings"]["mock"]
        savings_improvement = finetuned_savings - mock_savings
        
        print(f"  ğŸ“‰ TokenèŠ‚çœæå‡: {savings_improvement:+.1f} tokens ({savings_improvement/mock_savings*100:+.1f}%)")
        
        print("\\nğŸŠ æ€»ç»“:")
        if improvement > 0 and savings_improvement > 0:
            print("  ğŸŒŸ å¾®è°ƒæ¨¡å‹åœ¨å‡†ç¡®ç‡å’ŒTokenèŠ‚çœæ–¹é¢éƒ½æœ‰æå‡")
        elif improvement > 0:
            print("  âœ¨ å¾®è°ƒæ¨¡å‹åœ¨å‡†ç¡®ç‡æ–¹é¢æœ‰æ˜¾è‘—æå‡")
        elif savings_improvement > 0:
            print("  âš¡ å¾®è°ƒæ¨¡å‹åœ¨TokenèŠ‚çœæ–¹é¢æœ‰æ”¹è¿›")
        else:
            print("  ğŸ”§ å¾®è°ƒæ¨¡å‹æœ‰æ”¹è¿›ç©ºé—´ï¼Œå»ºè®®è¿›ä¸€æ­¥ä¼˜åŒ–")

def main():
    """ä¸»å‡½æ•°"""
    analyzer = TokenSavingsAnalyzer()
    
    # è¿è¡Œæµ‹è¯•
    results = analyzer.run_comprehensive_test()
    
    # ç”ŸæˆæŠ¥å‘Š
    analyzer.generate_report(results)
    
    # ä¿å­˜è¯¦ç»†ç»“æœ
    with open("reports/token_savings_analysis.json", "w", encoding="utf-8") as f:
        json.dump(results, f, ensure_ascii=False, indent=2)
    
    print(f"\\nâœ… è¯¦ç»†æµ‹è¯•ç»“æœå·²ä¿å­˜åˆ°: reports/token_savings_analysis.json")

if __name__ == "__main__":
    main()