#!/usr/bin/env python3
"""
TokenFlow æœåŠ¡å¯åŠ¨è„šæœ¬
"""

import os
import sys

# è®¾ç½®ç¯å¢ƒå˜é‡é¿å…MPSç›¸å…³é—®é¢˜
os.environ["PYTORCH_ENABLE_MPS_FALLBACK"] = "1"
os.environ["PYTORCH_MPS_HIGH_WATERMARK_RATIO"] = "0.0"
os.environ["OMP_NUM_THREADS"] = "1"
os.environ["MKL_NUM_THREADS"] = "1"
os.environ["TOKENIZERS_PARALLELISM"] = "false"

try:
    # å¯¼å…¥torchå¹¶è®¾ç½®CPUæ¨¡å¼
    import torch
    torch.set_num_threads(1)
    
    # ç¦ç”¨MPSåç«¯
    if hasattr(torch.backends, 'mps'):
        torch.backends.mps.is_available = lambda: False
    
    print("âœ… PyTorchç¯å¢ƒé…ç½®å®Œæˆ")
    
    # æµ‹è¯•ç»„ä»¶åˆå§‹åŒ–
    from src.classifiers.hybrid_intent_classifier import HybridIntentClassifier
    
    print("ğŸ§ª æµ‹è¯•æ··åˆæ„å›¾åˆ†ç±»å™¨åˆå§‹åŒ–...")
    classifier = HybridIntentClassifier("./models/intent_classifier_model_m3")
    
    print("ğŸ§ª æµ‹è¯•ç®€å•æ¨ç†...")
    result = classifier.predict_intent("æˆ‘æƒ³æŸ¥çœ‹æˆ‘çš„è®¢å•")
    print(f"æµ‹è¯•ç»“æœ: {result}")
    
    print("âœ… ç»„ä»¶æµ‹è¯•æˆåŠŸï¼Œå¯åŠ¨ä¸»åº”ç”¨...")
    
    # å¦‚æœæµ‹è¯•æˆåŠŸï¼Œå¯åŠ¨ä¸»åº”ç”¨
    from main import app
    import uvicorn
    
    uvicorn.run(app, host="0.0.0.0", port=8000)
    
except Exception as e:
    print(f"âŒ å¯åŠ¨å¤±è´¥: {e}")
    import traceback
    traceback.print_exc()
    sys.exit(1)